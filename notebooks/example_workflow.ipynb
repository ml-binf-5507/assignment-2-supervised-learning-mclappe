{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b453ce",
   "metadata": {},
   "source": [
    "# Assignment 2: Example Workflow\n",
    "\n",
    "This notebook demonstrates the complete workflow for Assignment 2.\n",
    "\n",
    "**Note**: This is a reference example. Your implementation may differ, but should follow these general steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f88f7",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ae856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "import seaborn as sns\n",
    "\n",
    "# Import your implementations\n",
    "from students import data_processing, regression, classification, evaluation\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a95d9",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab9343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = data_processing.load_heart_disease_data('data/heart.csv')\n",
    "print(f\"Loaded data shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum().sum()} total missing\")\n",
    "\n",
    "# Preprocess\n",
    "df_clean = data_processing.preprocess_data(df)\n",
    "print(f\"\\nPreprocessed data shape: {df_clean.shape}\")\n",
    "print(f\"Data types: {df_clean.dtypes.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeccaef",
   "metadata": {},
   "source": [
    "## Task 1: Linear Regression with ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare regression data\n",
    "X_reg, y_reg = data_processing.prepare_regression_data(df_clean, target='cholesterol')\n",
    "print(f\"Regression data shapes: X={X_reg.shape}, y={y_reg.shape}\")\n",
    "\n",
    "# Split and scale\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg, scaler_reg = data_processing.split_and_scale(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Train shape: {X_train_reg.shape}, Test shape: {X_test_reg.shape}\")\n",
    "\n",
    "# Train ElasticNet with grid search\n",
    "print(\"\\nTraining ElasticNet grid search...\")\n",
    "results = regression.train_elasticnet_grid(\n",
    "    X_train_reg, y_train_reg,\n",
    "    l1_ratios=[0.3, 0.5, 0.7],\n",
    "    alphas=[0.01, 0.1, 1.0]\n",
    ")\n",
    "print(f\"Grid search results shape: {results.shape}\")\n",
    "print(f\"R² range: {results['r2_score'].min():.3f} to {results['r2_score'].max():.3f}\")\n",
    "\n",
    "# Create heatmap\n",
    "fig = regression.create_r2_heatmap(\n",
    "    results,\n",
    "    [0.3, 0.5, 0.7],\n",
    "    [0.01, 0.1, 1.0]\n",
    ")\n",
    "plt.title('ElasticNet R² Scores')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Get best model\n",
    "reg_best = regression.get_best_elasticnet_model(\n",
    "    X_train_reg, y_train_reg, X_test_reg, y_test_reg,\n",
    "    l1_ratios=[0.3, 0.5, 0.7],\n",
    "    alphas=[0.01, 0.1, 1.0]\n",
    ")\n",
    "print(f\"\\nBest ElasticNet:\")\n",
    "print(f\"  l1_ratio: {reg_best['best_l1_ratio']}\")\n",
    "print(f\"  alpha: {reg_best['best_alpha']}\")\n",
    "print(f\"  Test R²: {reg_best['test_r2']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a7ddd3",
   "metadata": {},
   "source": [
    "## Tasks 2-3: Classification with Logistic Regression and k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98c5c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare classification data\n",
    "X_clf, y_clf = data_processing.prepare_classification_data(df_clean, target='heart_disease')\n",
    "print(f\"Classification data shapes: X={X_clf.shape}, y={y_clf.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y_clf.astype(int))}\")\n",
    "\n",
    "# Split and scale\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf, scaler_clf = data_processing.split_and_scale(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"\\nTrain shape: {X_train_clf.shape}, Test shape: {X_test_clf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed7126",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression\n",
    "print(\"Training Logistic Regression grid search...\")\n",
    "gs_lr = classification.train_logistic_regression_grid(X_train_clf, y_train_clf)\n",
    "print(f\"Best parameters: {gs_lr.best_params_}\")\n",
    "\n",
    "# Get best model\n",
    "lr_best = classification.get_best_logistic_regression(\n",
    "    X_train_clf, y_train_clf, X_test_clf, y_test_clf\n",
    ")\n",
    "print(f\"\\nLogistic Regression Test AUC: {lr_best['test_auc']:.3f}\")\n",
    "\n",
    "# Get probability predictions for curves\n",
    "y_pred_lr = lr_best['model'].predict_proba(X_test_clf)[:, 1]\n",
    "\n",
    "# Plot AUROC curve\n",
    "fig_lr = evaluation.generate_auroc_curve(y_test_clf, y_pred_lr, label='Logistic Regression')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3878f717",
   "metadata": {},
   "source": [
    "### k-NN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983564e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train k-NN\n",
    "print(\"Training k-NN grid search...\")\n",
    "gs_knn = classification.train_knn_grid(X_train_clf, y_train_clf)\n",
    "print(f\"Best parameters: {gs_knn.best_params_}\")\n",
    "\n",
    "# Get best model\n",
    "knn_best = classification.get_best_knn(\n",
    "    X_train_clf, y_train_clf, X_test_clf, y_test_clf\n",
    ")\n",
    "print(f\"\\nk-NN Test AUC: {knn_best['test_auc']:.3f}\")\n",
    "\n",
    "# Get probability predictions\n",
    "y_pred_knn = knn_best['model'].predict_proba(X_test_clf)[:, 1]\n",
    "\n",
    "# Plot AUROC curve\n",
    "fig_knn = evaluation.generate_auroc_curve(y_test_clf, y_pred_knn, label='k-NN')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99abcb3",
   "metadata": {},
   "source": [
    "## Task 4: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare AUROC curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# AUROC comparison\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test_clf, y_pred_lr)\n",
    "auc_lr = roc_auc_score(y_test_clf, y_pred_lr)\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test_clf, y_pred_knn)\n",
    "auc_knn = roc_auc_score(y_test_clf, y_pred_knn)\n",
    "\n",
    "axes[0].plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC={auc_lr:.3f})', linewidth=2)\n",
    "axes[0].plot(fpr_knn, tpr_knn, label=f'k-NN (AUC={auc_knn:.3f})', linewidth=2)\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', label='Random', alpha=0.5)\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('AUROC Curve Comparison')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# PR comparison\n",
    "precision_lr, recall_lr, _ = precision_recall_curve(y_test_clf, y_pred_lr)\n",
    "ap_lr = average_precision_score(y_test_clf, y_pred_lr)\n",
    "precision_knn, recall_knn, _ = precision_recall_curve(y_test_clf, y_pred_knn)\n",
    "ap_knn = average_precision_score(y_test_clf, y_pred_knn)\n",
    "\n",
    "axes[1].plot(recall_lr, precision_lr, label=f'Logistic Regression (AP={ap_lr:.3f})', linewidth=2)\n",
    "axes[1].plot(recall_knn, precision_knn, label=f'k-NN (AP={ap_knn:.3f})', linewidth=2)\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve Comparison')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Logistic Regression:\")\n",
    "print(f\"  AUROC: {auc_lr:.3f}\")\n",
    "print(f\"  AUPRC: {ap_lr:.3f}\")\n",
    "print(f\"\\nk-NN:\")\n",
    "print(f\"  AUROC: {auc_knn:.3f}\")\n",
    "print(f\"  AUPRC: {ap_knn:.3f}\")\n",
    "print(f\"\\nBetter model: {'Logistic Regression' if auc_lr > auc_knn else 'k-NN'}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c07ad",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Data Loading & Preprocessing**: Loading CSV, handling missing values, encoding categorical variables\n",
    "2. **ElasticNet Regression**: Grid search over l1_ratio and alpha, creating heatmap, evaluating test R²\n",
    "3. **Logistic Regression**: GridSearchCV, hyperparameter tuning, AUROC/AUPRC evaluation\n",
    "4. **k-NN Classification**: GridSearchCV, hyperparameter tuning, AUROC/AUPRC evaluation\n",
    "5. **Model Comparison**: Side-by-side AUROC and PR curves\n",
    "\n",
    "Your implementation should follow these same steps, though the specifics may differ."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
